### Dados na Cloud Azure ###

Este projeto tem como objetivo simular uma pipeline de dados completa, seguindo boas prÃ¡ticas de Engenharia de Dados, desde a ingestÃ£o atÃ© a persistÃªncia em Cloud e Banco de Dados.

A soluÃ§Ã£o foi construÃ­da em Python, com foco em qualidade de dados, estrutura profissional e preparaÃ§Ã£o para ambientes produtivos.

## ğŸ¯ Objetivo do Projeto ##

Simular um cenÃ¡rio real de engenharia de dados onde:

ğŸ“‚ Arquivos locais sÃ£o ingeridos

ğŸ”„ Dados sÃ£o transformados em DataFrames

âœ… Qualidade e schema sÃ£o validados com Pandera

â˜ï¸ Dados sÃ£o enviados para a Azure Blob Storage em formato Parquet

ğŸ—„ï¸ Dados sÃ£o persistidos em um Banco de Dados relacional via SQLAlchemy

## ğŸ§± Arquitetura da Pipeline ##

Fluxo lÃ³gico do processamento:

Arquivos Locais
      â†“
Pandas DataFrames
      â†“
ValidaÃ§Ã£o com Pandera
      â†“
Parquet (Azure Blob Storage)
      â†“
Insert no Banco de Dados


## ğŸ› ï¸ Tecnologias Utilizadas ##

Python 3.10+

Pandas â€“ ManipulaÃ§Ã£o de dados

Pandera â€“ ValidaÃ§Ã£o de schema e qualidade de dados

SQLAlchemy â€“ ORM e inserts controlados no banco

Azure Blob Storage â€“ Armazenamento em nuvem

Parquet â€“ Formato otimizado para dados analÃ­ticos

dotenv â€“ Gerenciamento de variÃ¡veis de ambiente

## â–¶ Como Executar o Projeto: ##

1ï¸âƒ£ Instalar as dependÃªncias
'pip install -r requirements.txt'

2ï¸âƒ£ Configurar variÃ¡veis de ambiente

Crie e preencha o arquivo .env_dev com as credenciais necessÃ¡rias, como:

- Azure Blob Storage

- Banco de Dados

- VariÃ¡veis de ambiente do projeto

3ï¸âƒ£ Executar a pipeline
'python main.py'

**â±ï¸ Tempo de ExecuÃ§Ã£o**

- âŒ› Primeira carga (full load): aproximadamente 15 minutos

_O tempo Ã© influenciado principalmente pela volumetria dos dados e pela escrita inicial no banco_

## âœ… Boas PrÃ¡ticas Aplicadas ##

- ValidaÃ§Ã£o de dados antes da persistÃªncia

- SeparaÃ§Ã£o clara de responsabilidades

- Uso de ORM para controle de tipos e defaults

- Logs estruturados para observabilidade

- Arquitetura preparada para evoluÃ§Ã£o (incremental, Airflow, dbt, etc.)

## ğŸ”® PrÃ³ximos Passos (EvoluÃ§Ã£o do Projeto) ##

- Implementar carga incremental

- OrquestraÃ§Ã£o com Airflow

- Camadas Bronze / Silver / Gold

- Testes automatizados de dados com dbt

- Monitoramento e alertas

**ğŸ‘¨â€ğŸ’» Autor: Nicolas CÃ©sar Nagel | Engenheiro de Dados / Analista de Dados**

_Projeto desenvolvido com foco em aprendizado prÃ¡tico, engenharia de dados moderna e padrÃµes de mercado, utilizando a stack Azure._